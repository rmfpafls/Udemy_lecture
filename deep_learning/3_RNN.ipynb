{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1g3a9oeJ0poelvEsV3nDRSV--lnGFrgzH",
      "authorship_tag": "ABX9TyMFqU2vjF6WWsOLYZXkpi5x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmfpafls/Udemy_lecture/blob/main/deep_learning/3_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEOa7uGeBC5x",
        "outputId": "9181a19e-f932-40c3-9c0d-038af9698307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. RNN"
      ],
      "metadata": {
        "id": "vsNvmfh6Bb2r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYojDdnSA9Cu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0abc35ec-7693-4dc7-c63d-0ae03fc72bda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\noutput\\n: (sequence_length, batch_size, hidden_size) 형태의 텐서로 나오고\\n: 입력 시퀀스의 각 타임스텝에서 나오는 출력을 포함한다.\\n: 각 입력에 대해 RNN이 출력하는 결과\\n_status (1, batch_size, hidden_size) 형태의 텐서\\n: 최종 타임스텝에서의 히든 상태 \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "input_size = 4\n",
        "hidden_size = 2\n",
        "\n",
        "h = [1, 0, 0, 0]\n",
        "e = [0, 1, 0, 0]\n",
        "l = [0, 0, 1, 0]\n",
        "o = [0, 0, 0, 1]\n",
        "\n",
        "input_data_np = np.array([[h, e, l, l, o],\n",
        "                          [e, o, l,l,l],\n",
        "                          [l, l, e, e, l]], dtype = np.float32)\n",
        "\n",
        "# transform as torch tensor\n",
        "input_data = torch.Tensor(input_data_np)\n",
        "\n",
        "rnn = torch.nn.RNN(input_size, hidden_size)\n",
        "outputs, _status = rnn(input_data)\n",
        "\n",
        "\"\"\"\n",
        "output\n",
        ": (sequence_length, batch_size, hidden_size) 형태의 텐서로 나오고\n",
        ": 입력 시퀀스의 각 타임스텝에서 나오는 출력을 포함한다.\n",
        ": 각 입력에 대해 RNN이 출력하는 결과\n",
        "_status (1, batch_size, hidden_size) 형태의 텐서\n",
        ": 최종 타임스텝에서의 히든 상태\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZyFGleb5z96",
        "outputId": "54ad64bf-a05a-4699-a474-855f8426cea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.2707, -0.5556],\n",
            "         [-0.5425, -0.7704],\n",
            "         [ 0.2042, -0.0196],\n",
            "         [ 0.2042, -0.0196],\n",
            "         [-0.4594, -0.3596]],\n",
            "\n",
            "        [[-0.6793, -0.8105],\n",
            "         [-0.8802, -0.4699],\n",
            "         [ 0.3107, -0.0265],\n",
            "         [ 0.3107, -0.0265],\n",
            "         [-0.3210, -0.0784]],\n",
            "\n",
            "        [[-0.6566, -0.1570],\n",
            "         [-0.5874, -0.0918],\n",
            "         [-0.4068, -0.7744],\n",
            "         [-0.4068, -0.7744],\n",
            "         [-0.0489, -0.0288]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(_status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v32zN4vI6Ijo",
        "outputId": "5cda9e02-30da-4617-ab8d-a378e693d423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.6566, -0.1570],\n",
            "         [-0.5874, -0.0918],\n",
            "         [-0.4068, -0.7744],\n",
            "         [-0.4068, -0.7744],\n",
            "         [-0.0489, -0.0288]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "# 2. hihello 문제"
      ],
      "metadata": {
        "id": "ieD9ApBeFCxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of available characters\n",
        "char_set = ['h', 'i', 'e', 'l', 'o']\n",
        "\n",
        "#hyper parameters\n",
        "input_size = len(char_set)\n",
        "hidden_size = len(char_set)\n",
        "learning_rate = 0.1\n",
        "\n",
        "# data setting\n",
        "x_data = [[0, 1, 0, 2, 3, 3]] # hihello 원핫인코딩의 인덱스 값\n",
        "x_one_hot = [[[1, 0, 0, 0, 0], # hihello의 원핫인코딩임\n",
        "              [0, 1, 0, 0, 0],\n",
        "              [1, 0, 0, 0, 0],\n",
        "              [0, 0, 1, 0, 0],\n",
        "              [0, 0, 0, 1, 0],\n",
        "              [0, 0, 0, 1, 0]]]\n",
        "y_data = [[1, 0, 2, 3, 3, 4]] # 예측할 대상 ihello\n",
        "\n",
        "# transform as torch tensor variable\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)\n"
      ],
      "metadata": {
        "id": "GoTVko_kBx8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code run through(charseq)\n",
        "\n",
        "sample = \"if you want you\"\n",
        "# make dictionary\n",
        "char_set = list(set(sample)) # set : python의 중복된 값들을 제거.\n",
        "print(char_set) # ['t', 'w', 'n', 'y', 'o', 'i', 'u', 'a', ' ', 'f']\n",
        "\n",
        "char_dic = {c: i for i, c in enumerate(char_set)}\n",
        "# 특정 character를 주면 그 index를 알아서 찾아주는 char_dic\n",
        "print(char_dic) # {'t': 0, 'w': 1, 'n': 2, 'y': 3, 'o': 4, 'i': 5, 'u': 6, 'a': 7, ' ': 8, 'f': 9}\n",
        "\n",
        "# hyper parameters\n",
        "dic_size = len(char_dic) # 중복을 제외한 글자들의 수\n",
        "hidden_size = dic_size\n",
        "learning_rate = 0.1\n",
        "\n",
        "# data setting\n",
        "sample_idx = [char_dic[c] for c in sample]\n",
        "# sample의 글자에 해당하는 idx\n",
        "\n",
        "x_data = [sample_idx[:-1]] # 얘는 처음부터 끝까지\n",
        "x_one_hot = [np.eye(dic_size)[x] for x in x_data] # 전체 사이즈 중에 x에 해당하는 값만 1\n",
        "y_data = [sample_idx[1:]]\n",
        "\n",
        "# transform as torch tensor variable\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxHMxkZ4GpG2",
        "outputId": "ebec8554-47b0-4cba-d973-87554c6d1474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['f', 'a', ' ', 'y', 't', 'o', 'i', 'u', 'n', 'w']\n",
            "{'f': 0, 'a': 1, ' ': 2, 'y': 3, 't': 4, 'o': 5, 'i': 6, 'u': 7, 'n': 8, 'w': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code run through\n",
        "# declare RNN\n",
        "import torch.optim as optim\n",
        "\n",
        "# X : x_one_hot\n",
        "# y = y_data\n",
        "\n",
        "rnn = torch.nn.RNN(input_size, hidden_size, batch_first = True)\n",
        "\n",
        "# loss & optimizer setting\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# Crossentropy loss : 2개의 확률 분포가 주어졌을 때, 그 확률 분포가 얼마나 비슷한지를 나타내는 것.\n",
        "optimizer = optim.Adam(rnn.parameters(), learning_rate)\n",
        "# pytorch에서 모델의 파라미터를 업데이트하기위해 Adam 최적화 기법을 사용하는 구문.\n",
        "# optim.Adam\n",
        "#: Adaptive Moment Estimation의 약자. 경사 하강법 기반의 최적화 알고리즘.\n",
        "#: 학습률을 자동으로 조정하며, 두 개의 모멘텀을 이요하여 그라디언트를 안정적으로 업데이트\n",
        "#: Adam 학습 속도를 가속화하면서도 과도한 진동을 억제하여, 일반적으로 많이 사용됨.\n",
        "\n",
        "#start training\n",
        "for i in range(100):\n",
        "  optimizer.zero_grad() # 초기화를 해줘야 매 plot마다 새로운 graient를 구할 수 있다.\n",
        "  outputs, _status = rnn(X)\n",
        "  # _status는 만약에 다음 input이 있으면, 그 다음 input은 RNN의 안에서 계산할 때 쓰이게 될 hidden state\n",
        "  # : 여기서는 주어진 모든 input을 다 처리하고 나오는 hidden state이기 때문에 따로 쓰이지 않는다.\n",
        "  loss = criterion(outputs.view(-1,input_size), Y.view(-1))\n",
        "  # shape를 batch_dimension이 앞에 오도록 시작하게끔 바꿔준 다음에 loss를 계산해주게 된다.\n",
        "  loss.backward() # backpropagation이 진행되고 gradient 값을 구하게 된다.\n",
        "  optimizer.step()\n",
        "  # 이 gradient 값을 토대로 optimizer.step()을 진행하면\n",
        "  # 아까 optimizer에 넣어뒀던 이 파라미터들에 대해서 업데이트를 하게 된다.\n",
        "\n",
        "\n",
        "# 모델이 실제로 어떻게 예측했는지에 대해서 알아보려고 하는 코드\n",
        "  result = outputs.data.numpy().argmax(axis = 2)\n",
        "  # output을 numpy array로 가져오고 그 다음에 여기서 argmax(axis = 2)를 해주면\n",
        "  # index = 2인 dimension.\n",
        "  # 즉, 어떤 character인지 나타내는 dimension에서 어떤 character가 가장 가능성 있는지에 대한\n",
        "  # 숫자를 가지고 있는데 이 중 가장 큰 숫자가 있는 index를 가져오는 함수가 argmax()임.\n",
        "  result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
        "  # np.squeeze(result) : shape에서 dimension이 1인 축을 없애주는 함수\n",
        "\n",
        "  print(i, \"loss : \", loss.item(), \"prediction : \", result, \"true Y : \", y_data, \"predicion str:\", result_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbfUZoqeOkjs",
        "outputId": "1d6b5474-0883-40f8-e19c-02c4f4dfe09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 loss :  1.7369784116744995 prediction :  [[3 1 4 1 4 0]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: lioioh\n",
            "1 loss :  1.5403571128845215 prediction :  [[3 0 3 2 4 3]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: lhleol\n",
            "2 loss :  1.4041223526000977 prediction :  [[3 0 3 3 3 3]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: lhllll\n",
            "3 loss :  1.2789825201034546 prediction :  [[3 0 2 3 3 3]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: lhelll\n",
            "4 loss :  1.1425503492355347 prediction :  [[3 0 2 3 3 3]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: lhelll\n",
            "5 loss :  1.0180224180221558 prediction :  [[3 0 2 3 0 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: lhelho\n",
            "6 loss :  0.9327946305274963 prediction :  [[3 0 2 3 0 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: lhelho\n",
            "7 loss :  0.8611664772033691 prediction :  [[1 0 2 3 0 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihelho\n",
            "8 loss :  0.7920508980751038 prediction :  [[1 0 2 3 0 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihelho\n",
            "9 loss :  0.7365986704826355 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "10 loss :  0.7071735858917236 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "11 loss :  0.6847591400146484 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "12 loss :  0.6540886759757996 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "13 loss :  0.632782518863678 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "14 loss :  0.6144594550132751 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "15 loss :  0.5949441194534302 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "16 loss :  0.5777471661567688 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "17 loss :  0.5665515065193176 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "18 loss :  0.5567060112953186 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "19 loss :  0.5455936193466187 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "20 loss :  0.5376052260398865 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "21 loss :  0.5317670106887817 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "22 loss :  0.5260506272315979 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "23 loss :  0.5201767683029175 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "24 loss :  0.5149532556533813 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "25 loss :  0.5112084746360779 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "26 loss :  0.5083353519439697 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "27 loss :  0.5049775242805481 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "28 loss :  0.5016911625862122 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "29 loss :  0.4989617168903351 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "30 loss :  0.49644264578819275 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "31 loss :  0.49436867237091064 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "32 loss :  0.4929095208644867 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "33 loss :  0.49117836356163025 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "34 loss :  0.48941293358802795 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "35 loss :  0.4880504906177521 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "36 loss :  0.48660293221473694 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "37 loss :  0.4852687120437622 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "38 loss :  0.4843935966491699 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "39 loss :  0.48332035541534424 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "40 loss :  0.4823572337627411 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "41 loss :  0.48157063126564026 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "42 loss :  0.4805958569049835 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "43 loss :  0.47982966899871826 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "44 loss :  0.4791671931743622 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "45 loss :  0.47841382026672363 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "46 loss :  0.4778949022293091 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "47 loss :  0.47728800773620605 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "48 loss :  0.47670498490333557 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "49 loss :  0.47622689604759216 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "50 loss :  0.47563910484313965 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "51 loss :  0.4751953184604645 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "52 loss :  0.4747191369533539 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "53 loss :  0.47427594661712646 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "54 loss :  0.4739048480987549 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "55 loss :  0.4734739363193512 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "56 loss :  0.473132848739624 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "57 loss :  0.4727407991886139 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "58 loss :  0.47239646315574646 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "59 loss :  0.4720582067966461 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "60 loss :  0.4717206060886383 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "61 loss :  0.4714277684688568 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "62 loss :  0.47110772132873535 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "63 loss :  0.47083738446235657 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "64 loss :  0.4705369174480438 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "65 loss :  0.470271497964859 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "66 loss :  0.4699949324131012 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "67 loss :  0.46973490715026855 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "68 loss :  0.4694828987121582 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "69 loss :  0.46923378109931946 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "70 loss :  0.46900150179862976 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "71 loss :  0.46876260638237 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "72 loss :  0.46854308247566223 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "73 loss :  0.4683131277561188 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "74 loss :  0.46810173988342285 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "75 loss :  0.4678819477558136 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "76 loss :  0.46767938137054443 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "77 loss :  0.467470645904541 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "78 loss :  0.46727633476257324 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "79 loss :  0.4670778512954712 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "80 loss :  0.4668906033039093 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "81 loss :  0.46669986844062805 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "82 loss :  0.466518372297287 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "83 loss :  0.4663349688053131 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "84 loss :  0.4661596715450287 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "85 loss :  0.4659833610057831 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "86 loss :  0.4658142626285553 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "87 loss :  0.46564456820487976 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "88 loss :  0.465481162071228 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "89 loss :  0.465317040681839 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "90 loss :  0.4651583433151245 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "91 loss :  0.4649994373321533 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "92 loss :  0.4648454487323761 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "93 loss :  0.4646916091442108 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "94 loss :  0.4645422399044037 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "95 loss :  0.46439334750175476 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "96 loss :  0.46424832940101624 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "97 loss :  0.464104026556015 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "98 loss :  0.4639626443386078 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n",
            "99 loss :  0.463822603225708 prediction :  [[1 0 2 3 3 4]] true Y :  [[1, 0, 2, 3, 3, 4]] predicion str: ihello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. longseq\n",
        "\n"
      ],
      "metadata": {
        "id": "Ugs7XeVQw147"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Making sequence dataset from long sentence\n",
        "sentence = (\"if you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\")\n",
        "\n",
        "# data setting\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "sequence_length = 10\n",
        "\n",
        "for i in range(0, len(sentence) - sequence_length):\n",
        "  x_str = sentence[i:i + sequence_length]\n",
        "  y_str = sentence[i+1:i + sequence_length + 1]\n",
        "\n",
        "  print(i, x_str, '->', y_str)\n",
        "\n",
        "  x_data.append([char_dic[c] for c in x_str])\n",
        "  y_data.append([char_dic[c] for c in y_str])\n",
        "\n",
        "x_one_hot = [np.eye(dic_size)[x] for x in x_data]\n",
        "\n",
        "# transform as torch tensor variable\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)\n",
        "\n",
        "# declare RNN + FC\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layers):\n",
        "    super(Net, self).__init__()\n",
        "    self.rnn = torch.nn.RNN(input_dim, hidden_dim, num_layers = layers, batch_first = True)\n",
        "    self.fc = torch.nn.Linear(hidden_dim, hidden_dim, bias = True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x, _status = self.rnn(x)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "net = Net(dic_size, hidden_size, 2)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = opim.Adam(net.parameters(), learning_rate)\n",
        "\n",
        "# start training\n",
        "for i in range(100):\n",
        "  optimizer.zero_grad()\n",
        "  outputs = net(x)\n",
        "  loss = criterion(outputs.view(-1, dic_size), Y.view(-1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  results = outputs.argmax(dim = 2 )\n",
        "  predict_str = \"\"\n",
        "\n",
        "  for j, result in enumerate(results):\n",
        "    print(i, j, ''.join([char_set[t] for t in result]), loss_item())\n",
        "    if j == 0:\n",
        "      predict_str += ''.join([char_set[t] for t in result])\n",
        "    else:\n",
        "      predict_str += char_set[result[-1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "110oY9OzxPX6",
        "outputId": "80dd385b-bb1d-48a6-8eec-3c721f3cac89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 if you wan -> f you want\n",
            "1 f you want ->  you want \n",
            "2  you want  -> you want t\n",
            "3 you want t -> ou want to\n",
            "4 ou want to -> u want to \n",
            "5 u want to  ->  want to b\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'b'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-b4d252306d16>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'->'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mx_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0my_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mx_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-b4d252306d16>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'->'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mx_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0my_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mx_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'b'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 시계열 데이터 RNN"
      ],
      "metadata": {
        "id": "tfU2Dh8wZqVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Random seed to make results deterministic and reproducible\n",
        "\n",
        "torch.manual_seed(0)\n",
        "# 코드가 실행될 때마다 같은 값이 생성되도록 보장해 주기 때문에, 결과의 일관성을 유지할 수 있습니다.\n",
        "\n",
        "def minmax_scaler(data):\n",
        "  numerator = data - np.min(data, 0)\n",
        "  denominator = np.max(data, 0) - np.min(data, 0)\n",
        "  return numerator / (denominator + 1e-7)\n",
        "\n",
        "# trainX, trainY = build_dataset(train_set, seq_length)\n",
        "# testX, testY = build_dataset(test_set, seq_length)\n",
        "\n",
        "def build_dataset(time_series, seq_length):\n",
        "  # 우리가 원하는 형태로 label과 학습에 대상이 되는 값들을 나눠주는 특성\n",
        "  dataX = []\n",
        "  dataY = []\n",
        "  for i in range(0, len(time_series)- seq_length):\n",
        "    _x = time_series[i: i+seq_length, :]\n",
        "    _y = time_series[i+seq_length, [-1]]\n",
        "    print(_x, \"->\", _y)\n",
        "    dataX.append(_x)\n",
        "    dataY.append(_y)\n",
        "  return np.array(dataX), np.array(dataY)\n",
        "\n",
        "# LSTM 모델 정의\n",
        "# net = Net(data_dim, hidden_dim, output_dim, 1)에서 부름\n",
        "class Net(torch.nn.Module): # nn선언\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, layers):\n",
        "    super(Net,self).__init__()\n",
        "    self.rnn = torch.nn.LSTM(input_dim, hidden_dim, num_layers = layers, batch_first = True)\n",
        "    self.fc = torch.nn.Linear(hidden_dim, output_dim, bias = True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x, _status = self.rnn(x)\n",
        "    x = self.fc(x[:,-1])\n",
        "    return x\n",
        "\n",
        "\n",
        "seq_length = 6\n",
        "data_dim = 5 # 시가, 최고가, 최저가, 거래량, 종량\n",
        "hidden_dim = 10\n",
        "output_dim = 1\n",
        "learning_rate = 0.01\n",
        "iterations = 500\n",
        "\n",
        "\n",
        "xy = np.loadtxt(\"/content/drive/MyDrive/boostcourse_딥러닝/google.dataset.csv\", delimiter = \",\")\n",
        "print(xy)\n",
        "xy = xy[::-1]\n",
        " # 불러온 data를 시간순의 역순으로\n",
        "\n",
        "train_size = int(len(xy) * 0.7)\n",
        "# 한번 ordering해주는 작업을 거친 후에 70%만 남기고, 70%는 학습 set에서 사용\n",
        "train_set = xy[0:train_size]\n",
        "test_set = xy[train_size - seq_length:]\n",
        "\n",
        "# minmax_scaler : 최대_최소 정규화\n",
        "train_set = minmax_scaler(train_set)\n",
        "test_set = minmax_scaler(test_set)\n",
        "# 스케일링을 하는 이유 : 숫자가 크면 계산하는데 부담이니까 0부터 1사이 값으로 바꿔준다\n",
        "\n",
        "# dataset 구축\n",
        "trainX, trainY = build_dataset(train_set, seq_length)\n",
        "testX, testY = build_dataset(test_set, seq_length)\n",
        "\n",
        "# 데이커를 pytorch tensor로 변환(3D 형태)\n",
        "trainX_tensor = torch.FloatTensor(trainX)\n",
        "trainY_tensor = torch.FloatTensor(trainY)\n",
        "\n",
        "testX_tensor = torch.FloatTensor(testX)\n",
        "testY_tensor = torch.FloatTensor(testY)\n",
        "\n",
        "print(\"trainX_tensor.shape:\", trainX_tensor.shape)  # (batch_size, seq_length, input_dim)\n",
        "print(\"trainY_tensor.shape:\", trainY_tensor.shape)  # (batch_size, 1)\n",
        "print(\"testX_tensor.shape:\", testX_tensor.shape)    # (batch_size, seq_length, input_dim)\n",
        "print(\"testY_tensor.shape:\", testY_tensor.shape)\n",
        "\n",
        "\n",
        "net = Net(data_dim, hidden_dim, output_dim, 1)\n",
        "\n",
        "criterion = torch.nn.MSELoss() # loss를 재고\n",
        "optimizer = optim.Adam(net.parameters(), lr = learning_rate) # Adam optimizer를 통해서 최적화 할거다\n",
        "\n",
        "## Training & Evaluation\n",
        "for i in range(iterations):\n",
        "  optimizer.zero_grad()\n",
        "  outputs = net(trainX_tensor)\n",
        "  loss = criterion(outputs, trainY_tensor)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(i,loss.item())\n",
        "\n",
        "plt.plot(testY)\n",
        "plt.plot(net(testX_tensor).data.numpy())\n",
        "plt.legend(['original', 'prediction'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "id": "EvhDuaRr0GE9",
        "outputId": "9cfa4440-cdff-475d-aab0-681fa4005571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.28659973e+02 8.33450012e+02 8.28349976e+02 1.24770000e+06\n",
            "  8.31659973e+02]\n",
            " [8.23020020e+02 8.28070007e+02 8.21655029e+02 1.59780000e+06\n",
            "  8.28070007e+02]\n",
            " [8.19929993e+02 8.24400024e+02 8.18979980e+02 1.28170000e+06\n",
            "  8.24159973e+02]\n",
            " [8.19359985e+02 8.23000000e+02 8.18469971e+02 1.30400000e+06\n",
            "  8.18979980e+02]\n",
            " [8.19000000e+02 8.23000000e+02 8.16000000e+02 1.05360000e+06\n",
            "  8.20450012e+02]\n",
            " [8.16000000e+02 8.20958984e+02 8.15489990e+02 1.19810000e+06\n",
            "  8.19239990e+02]\n",
            " [8.11700012e+02 8.15250000e+02 8.09780029e+02 1.12910000e+06\n",
            "  8.13669983e+02]\n",
            " [8.09510010e+02 8.10659973e+02 8.04539978e+02 9.89700000e+05\n",
            "  8.09559998e+02]\n",
            " [8.07000000e+02 8.11840270e+02 8.03190002e+02 1.15530000e+06\n",
            "  8.08380005e+02]]\n",
            "trainX_tensor.shape: torch.Size([0])\n",
            "trainY_tensor.shape: torch.Size([0])\n",
            "testX_tensor.shape: torch.Size([0])\n",
            "testY_tensor.shape: torch.Size([0])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "LSTM: Expected input to be 2D or 3D, got 1D instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-14dbb2825ef5>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-14dbb2825ef5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"LSTM: Expected input to be 2D or 3D, got {input.dim()}D instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m             \u001b[0mis_batched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m             \u001b[0mbatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: LSTM: Expected input to be 2D or 3D, got 1D instead"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 코드가 오류나는 이유는 data차원이 5차원인데 6개로 나눠서 계산하려고 했기때문. 수정하니 출력이 나오긴함.\n",
        "근데 예측을 전혀 못함;;\n",
        "\n",
        "seq_length를 1,2,3,4,5로 바꿔봤는데 2가 가장 비슷하게 나왔음"
      ],
      "metadata": {
        "id": "l3UWTPCLVMOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "seq_length = 2\n",
        "data_dim = 5 # 시가, 최고가, 최저가, 거래량, 종량\n",
        "hidden_dim = 5\n",
        "output_dim = 1\n",
        "learning_rate = 0.01\n",
        "iterations = 500\n",
        "\n",
        "\n",
        "xy = np.loadtxt(\"/content/drive/MyDrive/boostcourse_딥러닝/google.dataset.csv\", delimiter = \",\")\n",
        "xy = xy[::-1]\n",
        "# print(xy)\n",
        "\n",
        "# 데이터 나누기\n",
        "train_size = int(len(xy) * 0.7)\n",
        "# 한번 ordering해주는 작업을 거친 후에 70%만 남기고, 70%는 학습 set에서 사용\n",
        "train_set = xy[0:train_size]\n",
        "test_set = xy[train_size - seq_length:]\n",
        "\n",
        "# print(\"train_set :\", train_set)\n",
        "# print(\"test_set : \", test_set)\n",
        "\n",
        "# 최대최소 정규화\n",
        "def minmax_scaler(data):\n",
        "  numerator = data - np.min(data,0)\n",
        "  denominator = np.max(data, 0) - np.min(data, 0)\n",
        "  return numerator / (denominator + 1e-7) #a = 1e-7  # 0.0000001  b = 3e2   # 300.0 이런 표기법임\n",
        "train_set = minmax_scaler(train_set)\n",
        "test_set = minmax_scaler(test_set)\n",
        "# 스케일링을 하는 이유 : 숫자가 크면 계산하는데 부담이니까 0부터 1사이 값으로 바꿔준다\n",
        "\n",
        "# print(\"train_set\", train_set)\n",
        "# print(\"test_set\", test_set)\n",
        "\n",
        "# dataset 구축\n",
        "def build_dataset(time_series, seq_length): #  build_dataset(train_set, seq_length) 이렇게 들어감\n",
        "  dataX = []\n",
        "  dataY = []\n",
        "  # print(\"time_series\",len(time_series))\n",
        "  # print(\"seq_length\", seq_length)\n",
        "\n",
        "  for i in range(0, len(time_series) - seq_length):\n",
        "    _x = time_series[i : i+seq_length, :]\n",
        "    _y = time_series[i+seq_length, [-1]]\n",
        "    print(_x, '->', _y)\n",
        "    dataX.append(_x)\n",
        "    dataY.append(_y)\n",
        "  return np.array(dataX), np.array(dataY)\n",
        "\n",
        "trainX, trainY = build_dataset(train_set, seq_length) # train_set = 5x7, seq_length = 7\n",
        "testX, testY = build_dataset(test_set, seq_length)\n",
        "\n",
        "# 데이터를 pytorch tensor로 변환(3D 형태)\n",
        "trainX_tensor = torch.FloatTensor(trainX)\n",
        "trainY_tensor = torch.FloatTensor(trainY)\n",
        "\n",
        "testX_tensor = torch.FloatTensor(testX)\n",
        "testY_tensor = torch.FloatTensor(testY)\n",
        "\n",
        "if len(trainX_tensor.shape) == 2:\n",
        "    trainX_tensor = trainX_tensor.unsqueeze(-1)  # 입력 차원을 추가하여 (배치 크기, 시퀀스 길이, 입력 차원)\n",
        "if len(testX_tensor.shape) == 2:\n",
        "    testX_tensor = testX_tensor.unsqueeze(-1)\n",
        "\n",
        "print(\"train_set shape:\", train_set.shape)\n",
        "print(\"trainX_tensor.shape : \", trainX_tensor.shape)  # 기대하는 출력: (배치 크기, 시퀀스 길이, 입력 차원)\n",
        "print(\"testX_tensor.shape : \", testX_tensor.shape)\n",
        "\n",
        "# LSTM 모델 정의 (Long - short term memory)\n",
        "\"\"\"\n",
        "기본 RNN은 장기 의존성 문제를 겪는다.\n",
        "시간이 멀리 떨어진 시점에서의 정보를 잃어버리기 쉬운데 이는 기울기 소실 문제로 인해 발생한다.\n",
        "\n",
        "LSTM의 구성 요소 3가지 : 셀 상태(cell state), 입력 게이트(input gate), 출력 게이트(output gate)\n",
        "\n",
        "LSTM의 동작 과정\n",
        "1. 입력 및 이전 상태 수신 : 현재 입력 x_t와 이전 은닉 상태 h_t-1을 수신\n",
        "2. 입력 게이트 게산 : 입력 게이트에서 현재 입력과 이전 상태를 통해 새로운 정보의 비율을 결정\n",
        "3. 셀 상태 업데이트 : 이전 셀 상태에서 필터링된 정보를 반영하여 새로운 셀 상태를 계산\n",
        "4. 출력 게이트 계산 : 새로운 셀 상태에서 최종 출력을 계산\n",
        "5. 은닉 상태 업데이트 : 최종 출력을 통해 은닉 상태를 업데이트 합니다.\n",
        "\"\"\"\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, layers):\n",
        "    super(Net, self).__init__()\n",
        "    self.rnn = torch.nn.LSTM(input_dim, hidden_dim, num_layers = layers, batch_first = True)\n",
        "    # num_layers : LSTM의 층 수, 여러 층으로 쌓을 수 있어 복잡한 패턴을 학습할 수 있음\n",
        "    # batch_first = True : 입력 데이터의 배치 차원이 첫 번째에 온다는 것을 의미\n",
        "    self.fc = torch.nn.Linear(hidden_dim, output_dim, bias = True)\n",
        "    print(self.fc)\n",
        "\n",
        "  def forward(self, x): # 순전파 메서드\n",
        "    x, _status = self.rnn(x) # 입력 x를 LSTM 레이어에 통과시킴\n",
        "    x = self.fc(x[:,-1,:]) # LSTM이 출력 중 마지막 시점의 값을 선택\n",
        "    return x\n",
        "  \"\"\"\n",
        "  forward는 호출되지는 않는데 어떻게 쓰는거야?\n",
        "  : nn.Module을 상속받은 클래스에서는 내부적으로 모델 객체를 호출함으로써 자동으로 실행됨.\n",
        "  \"\"\"\n",
        "\n",
        "net = Net(data_dim, hidden_dim, output_dim, 1) # 1은 layer\n",
        "\n",
        "criterion = torch.nn.MSELoss() # loss를 재고\n",
        "\"\"\"\n",
        "MSE(평균제곱오차)\n",
        ": 예측 값과 실제 값의 차이(오차)의 제곱한 후, 평균\n",
        "\"\"\"\n",
        "optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
        "# Adam optimizer를 통해서 최적화 할거다\n",
        "\"\"\"\n",
        "net.parameters()\n",
        ": 네트워크의 모든 학습 가능한 파라미터를 반환.\n",
        ": Adam optimizer에 의해 학습 중 업데이트된다.\n",
        "\"\"\"\n",
        "\n",
        "## Training & Evaluation\n",
        "for i in range(iterations):\n",
        "  optimizer.zero_grad()\n",
        "  outputs = net(trainX_tensor)\n",
        "  loss = criterion(outputs, trainY_tensor)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(i,loss.item())\n",
        "\n",
        "plt.plot(testY)\n",
        "plt.plot(net(testX_tensor).data.numpy())\n",
        "plt.legend(['original', 'prediction'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WicEGj-DaqDN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ad432ad7-1f3f-4f50-caba-7bdfbfdc4046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.09564785 0.         0.52688514 0.        ]\n",
            " [0.20307549 0.         0.08834939 0.         0.09776241]] -> [0.43827464]\n",
            "[[0.20307549 0.         0.08834939 0.         0.09776241]\n",
            " [0.38026033 0.37196247 0.43128536 0.44352529 0.43827464]] -> [0.89974968]\n",
            "[[0.38026033 0.37196247 0.43128536 0.44352529 0.43827464]\n",
            " [0.72815622 0.83460198 0.80497466 0.66306077 0.89974968]] -> [0.99999999]\n",
            "[[0.72815622 0.83460198 0.80497466 0.66306077 0.89974968]\n",
            " [0.97087496 0.99999999 0.83835235 0.20330894 0.99999999]] -> [0.87820785]\n",
            "[[0.         0.         0.         0.         0.11593319]\n",
            " [0.03726563 0.         0.19999804 0.46012495 0.        ]] -> [0.40851702]\n",
            "[[0.03726563 0.         0.19999804 0.46012495 0.        ]\n",
            " [0.09627284 0.13397343 0.24129439 0.41914737 0.40851702]] -> [0.71687949]\n",
            "[[0.09627284 0.13397343 0.24129439 0.41914737 0.40851702]\n",
            " [0.4161523  0.48516757 0.45789797 1.         0.71687949]] -> [0.99999999]\n",
            "train_set shape: (6, 5)\n",
            "trainX_tensor.shape :  torch.Size([4, 2, 5])\n",
            "testX_tensor.shape :  torch.Size([3, 2, 5])\n",
            "Linear(in_features=5, out_features=1, bias=True)\n",
            "0 1.5988248586654663\n",
            "1 1.5236923694610596\n",
            "2 1.4497088193893433\n",
            "3 1.3767848014831543\n",
            "4 1.3048486709594727\n",
            "5 1.2337913513183594\n",
            "6 1.1634713411331177\n",
            "7 1.0937328338623047\n",
            "8 1.0244381427764893\n",
            "9 0.9554943442344666\n",
            "10 0.886870801448822\n",
            "11 0.8186124563217163\n",
            "12 0.7508462071418762\n",
            "13 0.6837818026542664\n",
            "14 0.6177086234092712\n",
            "15 0.5529860854148865\n",
            "16 0.49003052711486816\n",
            "17 0.42929962277412415\n",
            "18 0.37127581238746643\n",
            "19 0.316448450088501\n",
            "20 0.26529669761657715\n",
            "21 0.21827127039432526\n",
            "22 0.17577728629112244\n",
            "23 0.13815584778785706\n",
            "24 0.10566671937704086\n",
            "25 0.0784706100821495\n",
            "26 0.05661217123270035\n",
            "27 0.040004633367061615\n",
            "28 0.028416767716407776\n",
            "29 0.021464113146066666\n",
            "30 0.018607230857014656\n",
            "31 0.019160445779561996\n",
            "32 0.022315513342618942\n",
            "33 0.027185562998056412\n",
            "34 0.03287102282047272\n",
            "35 0.03854077309370041\n",
            "36 0.04350921884179115\n",
            "37 0.047288961708545685\n",
            "38 0.04960836470127106\n",
            "39 0.05039720609784126\n",
            "40 0.04974961280822754\n",
            "41 0.047876980155706406\n",
            "42 0.04505976289510727\n",
            "43 0.041604820638895035\n",
            "44 0.03781193494796753\n",
            "45 0.03394963592290878\n",
            "46 0.030240382999181747\n",
            "47 0.026853598654270172\n",
            "48 0.023904504254460335\n",
            "49 0.021457720547914505\n",
            "50 0.019533615559339523\n",
            "51 0.018116403371095657\n",
            "52 0.017162730917334557\n",
            "53 0.016610389575362206\n",
            "54 0.016386069357395172\n",
            "55 0.01641225628554821\n",
            "56 0.016612835228443146\n",
            "57 0.016917407512664795\n",
            "58 0.01726437360048294\n",
            "59 0.017602894455194473\n",
            "60 0.01789376512169838\n",
            "61 0.01810954324901104\n",
            "62 0.018233833834528923\n",
            "63 0.018260251730680466\n",
            "64 0.018190907314419746\n",
            "65 0.018034646287560463\n",
            "66 0.017805280163884163\n",
            "67 0.017519818618893623\n",
            "68 0.017196737229824066\n",
            "69 0.016854554414749146\n",
            "70 0.01651052013039589\n",
            "71 0.016179652884602547\n",
            "72 0.01587405800819397\n",
            "73 0.015602552331984043\n",
            "74 0.015370487235486507\n",
            "75 0.015179909765720367\n",
            "76 0.015029899775981903\n",
            "77 0.014917087741196156\n",
            "78 0.014836185611784458\n",
            "79 0.014780723489820957\n",
            "80 0.014743594452738762\n",
            "81 0.014717796817421913\n",
            "82 0.014696772210299969\n",
            "83 0.014674944803118706\n",
            "84 0.014647886157035828\n",
            "85 0.01461250800639391\n",
            "86 0.01456703431904316\n",
            "87 0.014510944485664368\n",
            "88 0.014444751664996147\n",
            "89 0.014369827695190907\n",
            "90 0.014288055710494518\n",
            "91 0.014201687648892403\n",
            "92 0.01411301176995039\n",
            "93 0.014024147763848305\n",
            "94 0.01393692847341299\n",
            "95 0.013852821663022041\n",
            "96 0.013772818259894848\n",
            "97 0.013697385787963867\n",
            "98 0.013626649975776672\n",
            "99 0.013560297898948193\n",
            "100 0.013497801497578621\n",
            "101 0.01343838032335043\n",
            "102 0.013381211087107658\n",
            "103 0.013325408101081848\n",
            "104 0.013270203955471516\n",
            "105 0.013214906677603722\n",
            "106 0.013158971443772316\n",
            "107 0.013102052733302116\n",
            "108 0.013043945655226707\n",
            "109 0.012984598986804485\n",
            "110 0.012924128212034702\n",
            "111 0.012862672097980976\n",
            "112 0.012800515629351139\n",
            "113 0.012737900018692017\n",
            "114 0.012675117701292038\n",
            "115 0.012612440623342991\n",
            "116 0.012550031766295433\n",
            "117 0.012488070875406265\n",
            "118 0.012426616623997688\n",
            "119 0.012365732342004776\n",
            "120 0.012305397540330887\n",
            "121 0.01224551908671856\n",
            "122 0.01218603178858757\n",
            "123 0.012126834131777287\n",
            "124 0.012067809700965881\n",
            "125 0.012008842080831528\n",
            "126 0.011949889361858368\n",
            "127 0.011890818364918232\n",
            "128 0.01183163933455944\n",
            "129 0.01177231501787901\n",
            "130 0.011712824925780296\n",
            "131 0.011653207242488861\n",
            "132 0.011593492701649666\n",
            "133 0.011533709242939949\n",
            "134 0.011473895981907845\n",
            "135 0.011414066888391972\n",
            "136 0.011354290880262852\n",
            "137 0.011294543743133545\n",
            "138 0.011234882287681103\n",
            "139 0.011175306513905525\n",
            "140 0.011115784756839275\n",
            "141 0.011056330986320972\n",
            "142 0.010996924713253975\n",
            "143 0.010937564074993134\n",
            "144 0.010878195986151695\n",
            "145 0.010818857699632645\n",
            "146 0.010759488679468632\n",
            "147 0.010700087063014507\n",
            "148 0.010640662163496017\n",
            "149 0.010581200942397118\n",
            "150 0.010521702468395233\n",
            "151 0.010462168604135513\n",
            "152 0.010402600280940533\n",
            "153 0.010342994704842567\n",
            "154 0.010283377021551132\n",
            "155 0.010223723948001862\n",
            "156 0.01016407273709774\n",
            "157 0.010104396380484104\n",
            "158 0.010044721886515617\n",
            "159 0.00998502317816019\n",
            "160 0.009925318881869316\n",
            "161 0.009865593165159225\n",
            "162 0.009805858135223389\n",
            "163 0.009746101684868336\n",
            "164 0.009686313569545746\n",
            "165 0.009626518003642559\n",
            "166 0.009566690772771835\n",
            "167 0.00950682908296585\n",
            "168 0.009446952491998672\n",
            "169 0.009387051686644554\n",
            "170 0.009327111765742302\n",
            "171 0.009267143905162811\n",
            "172 0.009207166731357574\n",
            "173 0.009147146716713905\n",
            "174 0.009087109006941319\n",
            "175 0.009027045220136642\n",
            "176 0.008966956287622452\n",
            "177 0.00890683475881815\n",
            "178 0.00884670577943325\n",
            "179 0.008786539547145367\n",
            "180 0.008726336061954498\n",
            "181 0.008666114881634712\n",
            "182 0.008605863898992538\n",
            "183 0.008545581251382828\n",
            "184 0.008485272526741028\n",
            "185 0.008424934931099415\n",
            "186 0.008364567533135414\n",
            "187 0.008304157294332981\n",
            "188 0.00824373122304678\n",
            "189 0.008183255791664124\n",
            "190 0.008122767321765423\n",
            "191 0.008062249049544334\n",
            "192 0.008001696318387985\n",
            "193 0.007941101677715778\n",
            "194 0.007880503311753273\n",
            "195 0.007819858379662037\n",
            "196 0.007759178522974253\n",
            "197 0.007698481902480125\n",
            "198 0.007637753151357174\n",
            "199 0.0075769927352666855\n",
            "200 0.007516222074627876\n",
            "201 0.00745541974902153\n",
            "202 0.007394592277705669\n",
            "203 0.007333725690841675\n",
            "204 0.007272844202816486\n",
            "205 0.007211942225694656\n",
            "206 0.007151009514927864\n",
            "207 0.0070900628343224525\n",
            "208 0.007029101252555847\n",
            "209 0.00696810707449913\n",
            "210 0.006907093804329634\n",
            "211 0.006846056319773197\n",
            "212 0.006785017438232899\n",
            "213 0.006723952013999224\n",
            "214 0.006662870291620493\n",
            "215 0.0066017769277095795\n",
            "216 0.0065406691282987595\n",
            "217 0.006479545496404171\n",
            "218 0.006418410688638687\n",
            "219 0.006357258185744286\n",
            "220 0.006296114064753056\n",
            "221 0.0062349517829716206\n",
            "222 0.006173782516270876\n",
            "223 0.00611260486766696\n",
            "224 0.006051426753401756\n",
            "225 0.005990239325910807\n",
            "226 0.005929050967097282\n",
            "227 0.005867872387170792\n",
            "228 0.00580669054761529\n",
            "229 0.005745512433350086\n",
            "230 0.005684332922101021\n",
            "231 0.0056231580674648285\n",
            "232 0.005561995320022106\n",
            "233 0.0055008539929986\n",
            "234 0.00543970987200737\n",
            "235 0.005378583446145058\n",
            "236 0.005317468196153641\n",
            "237 0.005256378557533026\n",
            "238 0.005195303820073605\n",
            "239 0.005134244449436665\n",
            "240 0.005073212087154388\n",
            "241 0.005012198816984892\n",
            "242 0.0049512144178152084\n",
            "243 0.004890270531177521\n",
            "244 0.004829341545701027\n",
            "245 0.00476845633238554\n",
            "246 0.004707599524408579\n",
            "247 0.0046467832289636135\n",
            "248 0.004586005583405495\n",
            "249 0.004525267984718084\n",
            "250 0.0044645750895142555\n",
            "251 0.004403941333293915\n",
            "252 0.004343346226960421\n",
            "253 0.004282797686755657\n",
            "254 0.004222318064421415\n",
            "255 0.004161889664828777\n",
            "256 0.004101527854800224\n",
            "257 0.004041229374706745\n",
            "258 0.0039809937588870525\n",
            "259 0.003920835442841053\n",
            "260 0.003860743949189782\n",
            "261 0.0038007439579814672\n",
            "262 0.003740820335224271\n",
            "263 0.00368098309263587\n",
            "264 0.0036212382838129997\n",
            "265 0.003561589401215315\n",
            "266 0.0035020513460040092\n",
            "267 0.0034426094498485327\n",
            "268 0.003383276518434286\n",
            "269 0.0033240672200918198\n",
            "270 0.0032649789936840534\n",
            "271 0.0032060137018561363\n",
            "272 0.003147188574075699\n",
            "273 0.003088506869971752\n",
            "274 0.0030299765057861805\n",
            "275 0.0029716002754867077\n",
            "276 0.002913386793807149\n",
            "277 0.00285535235889256\n",
            "278 0.0027974979020655155\n",
            "279 0.0027398341335356236\n",
            "280 0.0026823729276657104\n",
            "281 0.0026251147501170635\n",
            "282 0.002568090334534645\n",
            "283 0.002511298283934593\n",
            "284 0.002454749308526516\n",
            "285 0.0023984513245522976\n",
            "286 0.0023424343671649694\n",
            "287 0.0022866965737193823\n",
            "288 0.002231257501989603\n",
            "289 0.0021761301904916763\n",
            "290 0.0021213344298303127\n",
            "291 0.0020668734796345234\n",
            "292 0.0020127808675169945\n",
            "293 0.001959059154614806\n",
            "294 0.0019057358149439096\n",
            "295 0.0018528210930526257\n",
            "296 0.0018003406003117561\n",
            "297 0.0017483111005276442\n",
            "298 0.0016967474948614836\n",
            "299 0.0016456730663776398\n",
            "300 0.0015951113309711218\n",
            "301 0.0015450797509402037\n",
            "302 0.0014955990482121706\n",
            "303 0.001446696580387652\n",
            "304 0.0013983901590108871\n",
            "305 0.0013506999239325523\n",
            "306 0.001303651137277484\n",
            "307 0.0012572684790939093\n",
            "308 0.0012115702265873551\n",
            "309 0.001166580943390727\n",
            "310 0.0011223235633224249\n",
            "311 0.001078818691894412\n",
            "312 0.0010360907763242722\n",
            "313 0.0009941583266481757\n",
            "314 0.000953048758674413\n",
            "315 0.0009127705125138164\n",
            "316 0.000873352459166199\n",
            "317 0.0008348117116838694\n",
            "318 0.0007971671875566244\n",
            "319 0.0007604355923831463\n",
            "320 0.0007246355526149273\n",
            "321 0.0006897768471390009\n",
            "322 0.0006558778113685548\n",
            "323 0.0006229453720152378\n",
            "324 0.000590990821365267\n",
            "325 0.0005600295844487846\n",
            "326 0.0005300667835399508\n",
            "327 0.0005011028260923922\n",
            "328 0.0004731464432552457\n",
            "329 0.00044619987602345645\n",
            "330 0.00042026082519441843\n",
            "331 0.0003953281557187438\n",
            "332 0.0003714029735419899\n",
            "333 0.0003484721528366208\n",
            "334 0.0003265318810008466\n",
            "335 0.00030557543504983187\n",
            "336 0.00028558552730828524\n",
            "337 0.0002665524079930037\n",
            "338 0.00024845870211720467\n",
            "339 0.00023129075998440385\n",
            "340 0.0002150262735085562\n",
            "341 0.00019964887178502977\n",
            "342 0.0001851334673119709\n",
            "343 0.00017145769379567355\n",
            "344 0.00015859748236835003\n",
            "345 0.00014652674144599587\n",
            "346 0.0001352199469693005\n",
            "347 0.00012464827159419656\n",
            "348 0.00011478349915705621\n",
            "349 0.00010559738439042121\n",
            "350 9.706083801575005e-05\n",
            "351 8.91439412953332e-05\n",
            "352 8.181591692846268e-05\n",
            "353 7.504915993195027e-05\n",
            "354 6.881165609229356e-05\n",
            "355 6.307446165010333e-05\n",
            "356 5.780964784207754e-05\n",
            "357 5.298825999489054e-05\n",
            "358 4.858138709096238e-05\n",
            "359 4.456164606381208e-05\n",
            "360 4.090408401680179e-05\n",
            "361 3.758153980015777e-05\n",
            "362 3.456886042840779e-05\n",
            "363 3.1843890610616654e-05\n",
            "364 2.93829471047502e-05\n",
            "365 2.7165391657035798e-05\n",
            "366 2.5168228603433818e-05\n",
            "367 2.3375079763354734e-05\n",
            "368 2.1765148630947806e-05\n",
            "369 2.032234078797046e-05\n",
            "370 1.903089832921978e-05\n",
            "371 1.7874708646559156e-05\n",
            "372 1.684102062426973e-05\n",
            "373 1.591653926880099e-05\n",
            "374 1.5089295629877597e-05\n",
            "375 1.4348723198054358e-05\n",
            "376 1.3684139048564248e-05\n",
            "377 1.308756873186212e-05\n",
            "378 1.2550243809528183e-05\n",
            "379 1.2064768270647619e-05\n",
            "380 1.1624895705608651e-05\n",
            "381 1.1224487025174312e-05\n",
            "382 1.0858023415494245e-05\n",
            "383 1.0520752766751684e-05\n",
            "384 1.0209585525444709e-05\n",
            "385 9.919644980982412e-06\n",
            "386 9.648732884670608e-06\n",
            "387 9.393410437041894e-06\n",
            "388 9.151881386060268e-06\n",
            "389 8.92167827259982e-06\n",
            "390 8.701153092260938e-06\n",
            "391 8.489239917253144e-06\n",
            "392 8.28438533062581e-06\n",
            "393 8.08552977105137e-06\n",
            "394 7.892356734373607e-06\n",
            "395 7.703943083470222e-06\n",
            "396 7.519077371398453e-06\n",
            "397 7.33831893739989e-06\n",
            "398 7.161490430007689e-06\n",
            "399 6.987281267356593e-06\n",
            "400 6.816550012445077e-06\n",
            "401 6.64853178022895e-06\n",
            "402 6.483148354163859e-06\n",
            "403 6.320731699815951e-06\n",
            "404 6.161345027067e-06\n",
            "405 6.0049273997719865e-06\n",
            "406 5.850979960086988e-06\n",
            "407 5.699976554751629e-06\n",
            "408 5.55197948415298e-06\n",
            "409 5.406895070336759e-06\n",
            "410 5.264768333290704e-06\n",
            "411 5.125618372403551e-06\n",
            "412 4.98948065796867e-06\n",
            "413 4.856583018408855e-06\n",
            "414 4.7266421461245045e-06\n",
            "415 4.599430212692823e-06\n",
            "416 4.475425157579593e-06\n",
            "417 4.354539669293445e-06\n",
            "418 4.23707797381212e-06\n",
            "419 4.121966412640177e-06\n",
            "420 4.0099503166857176e-06\n",
            "421 3.900753199559404e-06\n",
            "422 3.7945292206131853e-06\n",
            "423 3.691068286570953e-06\n",
            "424 3.5901607589039486e-06\n",
            "425 3.4922099985124078e-06\n",
            "426 3.3966757655434776e-06\n",
            "427 3.3039727895811666e-06\n",
            "428 3.213679065083852e-06\n",
            "429 3.12576685246313e-06\n",
            "430 3.0402177344512893e-06\n",
            "431 2.9570892365882173e-06\n",
            "432 2.8765016395482235e-06\n",
            "433 2.7976079763902817e-06\n",
            "434 2.7210912776354235e-06\n",
            "435 2.646637767611537e-06\n",
            "436 2.5741646823007613e-06\n",
            "437 2.503576979506761e-06\n",
            "438 2.434981979604345e-06\n",
            "439 2.3683917333983118e-06\n",
            "440 2.3036172933643684e-06\n",
            "441 2.240268941022805e-06\n",
            "442 2.178710246880655e-06\n",
            "443 2.1188679966144264e-06\n",
            "444 2.0604950350389117e-06\n",
            "445 2.003858980970108e-06\n",
            "446 1.948622866621008e-06\n",
            "447 1.8948338720292668e-06\n",
            "448 1.842574874899583e-06\n",
            "449 1.7916491970026982e-06\n",
            "450 1.7419681626051897e-06\n",
            "451 1.6937791542659397e-06\n",
            "452 1.6467271279907436e-06\n",
            "453 1.6008442571546766e-06\n",
            "454 1.5564502291454119e-06\n",
            "455 1.512899984845717e-06\n",
            "456 1.4708332400914514e-06\n",
            "457 1.4297808093033382e-06\n",
            "458 1.3896786867917399e-06\n",
            "459 1.3506177083399962e-06\n",
            "460 1.3126755220582709e-06\n",
            "461 1.275776185138966e-06\n",
            "462 1.2398261333146365e-06\n",
            "463 1.2048753887938801e-06\n",
            "464 1.1708198144333437e-06\n",
            "465 1.1376545216990053e-06\n",
            "466 1.1053969046770362e-06\n",
            "467 1.0739764775280491e-06\n",
            "468 1.0433508350615739e-06\n",
            "469 1.0136525361303939e-06\n",
            "470 9.847401543083834e-07\n",
            "471 9.566626886226004e-07\n",
            "472 9.29149791772943e-07\n",
            "473 9.024751079778071e-07\n",
            "474 8.765440497882082e-07\n",
            "475 8.513530929121771e-07\n",
            "476 8.267403472927981e-07\n",
            "477 8.02898284746334e-07\n",
            "478 7.797395369379956e-07\n",
            "479 7.570531579403905e-07\n",
            "480 7.350656119342602e-07\n",
            "481 7.137272746149392e-07\n",
            "482 6.928964921826264e-07\n",
            "483 6.727588015564834e-07\n",
            "484 6.530612495225796e-07\n",
            "485 6.340604272736527e-07\n",
            "486 6.15419367022696e-07\n",
            "487 5.973848828944028e-07\n",
            "488 5.798075335405883e-07\n",
            "489 5.627382506645517e-07\n",
            "490 5.461597538669594e-07\n",
            "491 5.300675525177212e-07\n",
            "492 5.143926955497591e-07\n",
            "493 4.992253366253863e-07\n",
            "494 4.843012106903188e-07\n",
            "495 4.6997743652354984e-07\n",
            "496 4.560428692457208e-07\n",
            "497 4.424280746206932e-07\n",
            "498 4.2927621279886807e-07\n",
            "499 4.164317033428233e-07\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Seq2Seq"
      ],
      "metadata": {
        "id": "JbLZ7pgRV4uI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 내용은 옵시디언에"
      ],
      "metadata": {
        "id": "GVaXBhMfatWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Seq2Seq : Encoder-Decoder\n",
        "# 간략하게 Encoder - Decoder가 어떻게 되는지만 보자면\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "cjMEBC8cmFxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 코드가 실행되는 부분\n",
        "# 번역 task를 수행하는 seq2seq model을 구현한 코드\n",
        "\n",
        "SOURCE_MAX_LENGTH = 10 # 영어문장\n",
        "TARGET_MAX_LENGTH = 12 # 영어문장을 번역한 한국어 문장\n",
        "load_pairs, load_source_vocab, load_target_vocab = preprocess(raw, SOURCE_MAX_LENGTH,TARGET_MAX_LENGTH)\n",
        "# raw : 원문\n",
        "# preprocess 과정 - 0.7은 내가 가정한 거임\n",
        "# : source 데이터와 target 데이터 test 데이터(s : 70%, t : 70%)와  target 데이터(s : 30%, t : 30%)으로 나누는 과정\n",
        "# : 이때, source와 target 문장의 최대 길이도 제한해준다.\n",
        "print(random.choice(load_pairs))\n",
        "\n",
        "#encoder의 hidden state 사이즈와 decoder의 hidden state 사이즈를 정의해준다.\n",
        "enc_hidden_size = 16\n",
        "dec_hidden_size = enc_hidden_size\n",
        "\n",
        "# Encoder, Decoder라는 RNN layer를 정의해준다.\n",
        "# 강사 : 이 encoder, decoder의 한계가 있는데, 이 한계를 극복하기 위해서 더 복잡한 구조를 넣거나 수정하는건 여러분 몫\n",
        "enc = Encoder(load_source_vocab.n_vocab, enc_hidden_size).to(device)\n",
        "# Encoder에서는 Encoder의 아웃풋을 decoder로 넘겨주는 코드가 있겠구나~하고 추측할 수 있음\n",
        "dec = Decoder(dec_hidden_size, load_target_vocab.n_vocab).to(device)\n",
        "\n",
        "train(load_pairs, load_source_vocab, load_target_vocab, enc, dec, 5000, print_every = 1000)\n",
        "evaluate(load_pairs, load_source_vocab, load_target_vocab, enc, dec, TARGET_MAX_LENGTH )"
      ],
      "metadata": {
        "id": "Fpz0sAuxMjFQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "0281fa25-6498-4ca7-b0e5-46ff22f93573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading corpus...\n",
            "Read 4 sentence pairs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'filter_pair' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-19a36d178c4b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mSOURCE_MAX_LENGTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;31m# 영어문장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTARGET_MAX_LENGTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;31m# 영어문장을 번역한 한국어 문장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mload_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_source_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_target_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOURCE_MAX_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTARGET_MAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# preprocess 과정 - 0.7은 내가 가정한 거임\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# : source 데이터와 target 데이터 test 데이터(s : 70%, t : 70%)와  target 데이터(s : 30%, t : 30%)으로 나누는 과정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-7970d4baafa6>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(corpus, source_max_length, target_max_length)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read {} sentence pairs\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilter_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_max_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trimmed to {} sentence pairs\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-7970d4baafa6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read {} sentence pairs\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilter_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_max_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trimmed to {} sentence pairs\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'filter_pair' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 위 코드를 이제 짜보자!\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# pytorch에서 모델이 실행될 장치를 설정하는 코드\n",
        "# torch.device() : pytorch에서 device는 텐서와 모델이 연산될 장치를 나타냄\n",
        "# torch.cuda.is_available() : 사용 가능한 GPU가 있는지 확인하는 함수, 있다면 True 아니면 False\n",
        "\n",
        "\n",
        "raw = [\"I feel hungry.  나는 배가 고프다\",\n",
        "       \"Pytorch is very easy. 파이토치는 매우 쉽다.\",\n",
        "       \"Pytorch is a framwork for deep learning.  파이토치는 딥러닝을 위한 프레임워크이다.\",\n",
        "       \"Pytorch is very clear to use. 파이토치는 사용하기 매우 직관적이다.\"\n",
        "       ]\n",
        "\n",
        "SOS_token = 0 # Start of sentence\n",
        "EOS_token = 1 # End of sentence : 문장이 끝나면 EOS라는 token을 붙여가지고 이 문장의 종료를 알려준다.\n",
        "# decoder가 hidden state로 encoder의 마지막 출력물을 받아오고\n",
        "# 첫번째 step의 input을 받아야됨.\n",
        "# 그 step의 input으로 SOS_token을 넣어주게 된다.\n",
        "# 그걸 뜻하는 token의 index를 0번으로 준다.\n"
      ],
      "metadata": {
        "id": "BJxzf4hfh44x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing\n",
        "def preprocess(corpus, source_max_length, target_max_length):\n",
        "  print(\"reading corpus...\")\n",
        "  pairs = []\n",
        "  for line in corpus:\n",
        "    pairs.append([s for s in line.strip().lower().split(\"\\t\")])\n",
        "  print(\"Read {} sentence pairs\".format(len(pairs)))\n",
        "\n",
        "  pairs = [pair for pair in pairs if filter_pair(pair, source_max_length, target_max_length)]\n",
        "  print(\"Trimmed to {} sentence pairs\".format(len(pairs)))\n",
        "\n",
        "  source_vocab = Vocab()\n",
        "  target_vocab = Vocab()\n",
        "\n",
        "  print(\"Counting words...\")\n",
        "  for pair in pairs:\n",
        "    source_vocab.add_vocab(pair[0])\n",
        "    target_vocab.add_vocab(pair[1])\n",
        "\n",
        "  print(\"source vocab size = \", source_vocab.n_vocab)\n",
        "  print(\"taget vocab size = \", taget_vocab.n_vocab)\n",
        "\n",
        "  return pairs, source_vocab, target_vocab"
      ],
      "metadata": {
        "id": "y7bjzMmGkrOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    # input_size : 사용되고 있는 단어의 갯수,\n",
        "    # source text에 있는 각각의 단어들은 100개의 차원을 가지는 one-hot encodding으로 표현이 가능\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    x = self.embedding(x).view(1, 1, -1)\n",
        "    # Embedding : one-hot encodding으로 표현된 것들이 input으로 들어가고, hidden_size만큼의 vetor로 줄이는 matrix\n",
        "    x, hidden = self.gru(x, hidden) # 줄어든 x가 gru에 들어가서 hidden과 계산\n",
        "    return x, hidden"
      ],
      "metadata": {
        "id": "VmftcsdNFsfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super(Decoder, self).__init()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    x = self.embedding(x).view(1, 1, -1) # embedding 통과\n",
        "    x, hidden = self.gru(x, hidden) # gru 통과\n",
        "    x = self.softmax(self.out(x[0])) # out 통과해서 softmax 통과해서 나오게 된다.\n",
        "    return x, hidden"
      ],
      "metadata": {
        "id": "Gmuun5ryaIsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "def tensorize(vocab, sentence): # sentence를 one-hot vector로 만들어주는 역할\n",
        "  indexes = [vocab.vocab2index[word] for word in sentence.split(\"  \")]\n",
        "  indexes.append(vocab.vocab2index[\"<EOS>\"])\n",
        "  return torch.Tensor(indexes).long().to(device).view(-1,1)\n",
        "\n",
        "def train(pairs, source_vocab, target_vocab, encoder, decoder, n_iter, print_every = 1000, learning_rate = 0.01):\n",
        "  loss_total = 0\n",
        "\n",
        "  encoder_optimizer = optim.SGD(encoder.paramaters(), lr = learning_rate)\n",
        "  decoder_optimizer = optim.SGD(decoder.paramaters(), lr = learning_rate)\n",
        "\n",
        "  training_batch = [random.choice(pairs) for _ in range(n_iter)]\n",
        "  # 전체 dataset에서 필요한 개수만큼 random하게 학습 datat를 추출\n",
        "  training_source = [tensorize(sorce_vocab, pair[0]) for pair in training_batch]\n",
        "  training_target = [tensorize(target_vocab, pair[1]) for pair in training_batch]\n",
        "\n",
        "  criterion = nn.MLLLoss() # loss를 재는 방법\n",
        "\n",
        "  for i in range(1, n_iter + 1):\n",
        "    source_tensor = training_source[i - 1]\n",
        "    target_tensor = training_target[i - 1]\n",
        "\n",
        "    encoder_hidden = torch.zeros([1,1,encoder.hidden_size]).to(device)\n",
        "    # 맨 처음 encoder의 hidden state에 들어가는 값이 없으니까. 0 vector로 다 만들어가지고 넣어준다.\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    souce_length = source_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for enc_input in range(source_length):\n",
        "      # 문장이 끝날때까지 loop를 돌면서 encoder에서 hidden state를 꺼내온다.\n",
        "      _, encoder_hidden = encoder(source_tensor[enc_input], encoder_hidden)\n",
        "\n",
        "      decoder_input  = torch.Tensor([[SOS_token]]).long().to(device)\n",
        "      decoder_hidden = encoder_hidden\n",
        "\n",
        "      for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        loss += criterion(decoder_output, target_tensor[di])\n",
        "        decoder_input = target_tensor[di] # teacher forcing\n",
        "        # teacher forcing 이란?\n",
        "        # 보통 시퀀스 에측 모델을 이전 단계의 출력을 다음 단계의 입력으로 사용된다,\n",
        "        # 하지만 학습 중에는 이 방식이 정확하지 않을 수 있음. 모델이 아직 충분히 학습되지 않았기 때문에\n",
        "        # 초기에 잘못된 예측을 할 가능성이 높음. -> 그래서 teacher forcing를 사용\n",
        "        # : 학습 중에 이전 단계의 예측값을 다음 입력으로 사용하는 대신, '실제 정답'을 다음 입력으로 사용\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      encoder_optimizer.step()\n",
        "      decoder_optimizer.step()\n",
        "\n",
        "      loss_iter = loss.item() / target_length\n",
        "      loss_total += loss_iter\n",
        "\n",
        "      if i % print_every == 0:\n",
        "        loss_avg = loss_total / print_every\n",
        "        loss_total = 0\n",
        "        print(\"[{} - {}%] loss = {:05.4f}\".format(i, i / n_iter * 100, loss_avg))"
      ],
      "metadata": {
        "id": "2nhWuwKKusJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "위 코드 정리\n"
      ],
      "metadata": {
        "id": "NpaGUpNcLgFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 번역 task를 수행하는 seq2seq model을 구현한 코드\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# pytorch에서 모델이 실행될 장치를 설정하는 코드\n",
        "# torch.device() : pytorch에서 device는 텐서와 모델이 연산될 장치를 나타냄\n",
        "# torch.cuda.is_available() : 사용 가능한 GPU가 있는지 확인하는 함수, 있다면 True 아니면 False\n",
        "\n",
        "# 1. preprocessing\n",
        "# preprocess(raw, SOURCE_MAX_LENGTH,TARGET_MAX_LENGTH)으로 호출함. raw는 원문\n",
        "def preprocess(corpus, source_max_length, target_max_length):\n",
        "  print(\"reading corpus...\")\n",
        "  pairs = []\n",
        "  for line in corpus:\n",
        "    pairs.append([s for s in line.strip().lower().split(\"\\t\")])\n",
        "    print(\"paris : \", pairs)\n",
        "    # paris :  [['i feel hungry.  나는 배가 고프다'], ['pytorch is very easy. 파이토치는 매우 쉽다.'], ['pytorch is a framwork for deep learning.  파이토치는 딥러닝을 위한 프레임워크이다.'], ['pytorch is very clear to use. 파이토치는 사용하기 매우 직관적이다.']]\n",
        "  print(\"Read {} sentence pairs\".format(len(pairs)))\n",
        "\n",
        "  pairs = [pair for pair in pairs if filter_pair(pair, source_max_length, target_max_length)]\n",
        "  print(\"Trimmed to {} sentence pairs\".format(len(pairs)))\n",
        "\n",
        "  source_vocab = Vocab()\n",
        "  target_vocab = Vocab()\n",
        "\n",
        "  print(\"Counting words...\")\n",
        "  for pair in pairs:\n",
        "    source_vocab.add_vocab(pair[0])\n",
        "    target_vocab.add_vocab(pair[1])\n",
        "\n",
        "  print(\"source vocab size = \", source_vocab.n_vocab)\n",
        "  print(\"taget vocab size = \", taget_vocab.n_vocab)\n",
        "\n",
        "  return pairs, source_vocab, target_vocab\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    # input_size : 사용되고 있는 단어의 갯수,\n",
        "    # source text에 있는 각각의 단어들은 100개의 차원을 가지는 one-hot encodding으로 표현이 가능\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    x = self.embedding(x).view(1, 1, -1)\n",
        "    # Embedding : one-hot encodding으로 표현된 것들이 input으로 들어가고, hidden_size만큼의 vetor로 줄이는 matrix\n",
        "    x, hidden = self.gru(x, hidden) # 줄어든 x가 gru에 들어가서 hidden과 계산\n",
        "    return x, hidden\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super(Decoder, self).__init()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    x = self.embedding(x).view(1, 1, -1) # embedding 통과\n",
        "    x, hidden = self.gru(x, hidden) # gru 통과\n",
        "    x = self.softmax(self.out(x[0])) # out 통과해서 softmax 통과해서 나오게 된다.\n",
        "    return x, hidden\n",
        "\n",
        "# Training\n",
        "def tensorize(vocab, sentence): # sentence를 one-hot vector로 만들어주는 역할\n",
        "  indexes = [vocab.vocab2index[word] for word in sentence.split(\"  \")]\n",
        "  indexes.append(vocab.vocab2index[\"<EOS>\"])\n",
        "  return torch.Tensor(indexes).long().to(device).view(-1,1)\n",
        "\n",
        "def train(pairs, source_vocab, target_vocab, encoder, decoder, n_iter, print_every = 1000, learning_rate = 0.01):\n",
        "  loss_total = 0\n",
        "\n",
        "  encoder_optimizer = optim.SGD(encoder.paramaters(), lr = learning_rate)\n",
        "  decoder_optimizer = optim.SGD(decoder.paramaters(), lr = learning_rate)\n",
        "\n",
        "  training_batch = [random.choice(pairs) for _ in range(n_iter)]\n",
        "  # 전체 dataset에서 필요한 개수만큼 random하게 학습 datat를 추출\n",
        "  training_source = [tensorize(sorce_vocab, pair[0]) for pair in training_batch]\n",
        "  training_target = [tensorize(target_vocab, pair[1]) for pair in training_batch]\n",
        "\n",
        "  criterion = nn.NLLLoss() # loss를 재는 방법\n",
        "\n",
        "  for i in range(1, n_iter + 1):\n",
        "    source_tensor = training_source[i - 1]\n",
        "    target_tensor = training_target[i - 1]\n",
        "\n",
        "    encoder_hidden = torch.zeros([1,1,encoder.hidden_size]).to(device)\n",
        "    # 맨 처음 encoder의 hidden state에 들어가는 값이 없으니까. 0 vector로 다 만들어가지고 넣어준다.\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    souce_length = source_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for enc_input in range(source_length):\n",
        "      # 문장이 끝날때까지 loop를 돌면서 encoder에서 hidden state를 꺼내온다.\n",
        "      _, encoder_hidden = encoder(source_tensor[enc_input], encoder_hidden)\n",
        "\n",
        "      decoder_input  = torch.Tensor([[SOS_token]]).long().to(device)\n",
        "      decoder_hidden = encoder_hidden\n",
        "\n",
        "      for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        loss += criterion(decoder_output, target_tensor[di])\n",
        "        decoder_input = target_tensor[di] # teacher forcing\n",
        "        # teacher forcing 이란?\n",
        "        # 보통 시퀀스 에측 모델을 이전 단계의 출력을 다음 단계의 입력으로 사용된다,\n",
        "        # 하지만 학습 중에는 이 방식이 정확하지 않을 수 있음. 모델이 아직 충분히 학습되지 않았기 때문에\n",
        "        # 초기에 잘못된 예측을 할 가능성이 높음. -> 그래서 teacher forcing를 사용\n",
        "        # : 학습 중에 이전 단계의 예측값을 다음 입력으로 사용하는 대신, '실제 정답'을 다음 입력으로 사용\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      encoder_optimizer.step()\n",
        "      decoder_optimizer.step()\n",
        "\n",
        "      loss_iter = loss.item() / target_length\n",
        "      loss_total += loss_iter\n",
        "\n",
        "      if i % print_every == 0:\n",
        "        loss_avg = loss_total / print_every\n",
        "        loss_total = 0\n",
        "        print(\"[{} - {}%] loss = {:05.4f}\".format(i, i / n_iter * 100, loss_avg))\n",
        "\n",
        "\n",
        "raw = [\"I feel hungry.  나는 배가 고프다\",\n",
        "       \"Pytorch is very easy. 파이토치는 매우 쉽다.\",\n",
        "       \"Pytorch is a framwork for deep learning.  파이토치는 딥러닝을 위한 프레임워크이다.\",\n",
        "       \"Pytorch is very clear to use. 파이토치는 사용하기 매우 직관적이다.\"\n",
        "       ]\n",
        "\n",
        "SOS_token = 0 # Start of sentence\n",
        "EOS_token = 1 # End of sentence : 문장이 끝나면 EOS라는 token을 붙여가지고 이 문장의 종료를 알려준다.\n",
        "# decoder가 hidden state로 encoder의 마지막 출력물을 받아오고\n",
        "# 첫번째 step의 input을 받아야됨.\n",
        "# 그 step의 input으로 SOS_token을 넣어주게 된다.\n",
        "# 그걸 뜻하는 token의 index를 0번으로 준다.\n",
        "\n",
        "# 전체 코드가 실행되는 부분\n",
        "\n",
        "SOURCE_MAX_LENGTH = 10 # 영어 문장의 최대 길이를 10 단어로 제한한다.\n",
        "TARGET_MAX_LENGTH = 12 # 한국어 번역 문장의 최대 길이를 12 단어로 제한한다.\n",
        "load_pairs, load_source_vocab, load_target_vocab = preprocess(raw, SOURCE_MAX_LENGTH,TARGET_MAX_LENGTH)\n",
        "# raw : 원문\n",
        "# preprocess 과정 - 0.7은 내가 가정한 거임\n",
        "# : source 데이터와 target 데이터 test 데이터(s : 70%, t : 70%)와  target 데이터(s : 30%, t : 30%)으로 나누는 과정\n",
        "# : 이때, source와 target 문장의 최대 길이도 제한해준다.\n",
        "print(random.choice(load_pairs))\n",
        "\n",
        "#encoder의 hidden state 사이즈와 decoder의 hidden state 사이즈를 정의해준다.\n",
        "enc_hidden_size = 16\n",
        "dec_hidden_size = enc_hidden_size\n",
        "\n",
        "# Encoder, Decoder라는 RNN layer를 정의해준다.\n",
        "# 강사 : 이 encoder, decoder의 한계가 있는데, 이 한계를 극복하기 위해서 더 복잡한 구조를 넣거나 수정하는건 여러분 몫\n",
        "enc = Encoder(load_source_vocab.n_vocab, enc_hidden_size).to(device)\n",
        "# Encoder에서는 Encoder의 아웃풋을 decoder로 넘겨주는 코드가 있겠구나~하고 추측할 수 있음\n",
        "dec = Decoder(dec_hidden_size, load_target_vocab.n_vocab).to(device)\n",
        "\n",
        "train(load_pairs, load_source_vocab, load_target_vocab, enc, dec, 5000, print_every = 1000)\n",
        "evaluate(load_pairs, load_source_vocab, load_target_vocab, enc, dec, TARGET_MAX_LENGTH )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "xLh7sq_CLfpP",
        "outputId": "628da78d-ee4d-41e1-8c69-e8532f673efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading corpus...\n",
            "paris :  [['i feel hungry.  나는 배가 고프다']]\n",
            "paris :  [['i feel hungry.  나는 배가 고프다'], ['pytorch is very easy. 파이토치는 매우 쉽다.']]\n",
            "paris :  [['i feel hungry.  나는 배가 고프다'], ['pytorch is very easy. 파이토치는 매우 쉽다.'], ['pytorch is a framwork for deep learning.  파이토치는 딥러닝을 위한 프레임워크이다.']]\n",
            "paris :  [['i feel hungry.  나는 배가 고프다'], ['pytorch is very easy. 파이토치는 매우 쉽다.'], ['pytorch is a framwork for deep learning.  파이토치는 딥러닝을 위한 프레임워크이다.'], ['pytorch is very clear to use. 파이토치는 사용하기 매우 직관적이다.']]\n",
            "Read 4 sentence pairs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'filter_pair' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-2737bfac5d97>\u001b[0m in \u001b[0;36m<cell line: 156>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0mSOURCE_MAX_LENGTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;31m# 영어 문장의 최대 길이를 10 단어로 제한한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0mTARGET_MAX_LENGTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;31m# 한국어 번역 문장의 최대 길이를 12 단어로 제한한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m \u001b[0mload_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_source_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_target_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOURCE_MAX_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTARGET_MAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;31m# raw : 원문\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;31m# preprocess 과정 - 0.7은 내가 가정한 거임\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-2737bfac5d97>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(corpus, source_max_length, target_max_length)\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read {} sentence pairs\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilter_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_max_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trimmed to {} sentence pairs\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-2737bfac5d97>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read {} sentence pairs\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilter_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_max_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trimmed to {} sentence pairs\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'filter_pair' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Vocab 클래스 정의\n",
        "class Vocab:\n",
        "    def __init__(self):\n",
        "        self.vocab2index = {\"<SOS>\": 0, \"<EOS>\": 1}  # SOS와 EOS 토큰 추가\n",
        "        self.index2vocab = {0: \"<SOS>\", 1: \"<EOS>\"}\n",
        "        self.n_vocab = 2  # SOS와 EOS로 시작\n",
        "\n",
        "    def add_vocab(self, sentence):\n",
        "        for word in sentence.split():\n",
        "            if word not in self.vocab2index:\n",
        "                self.vocab2index[word] = self.n_vocab\n",
        "                self.index2vocab[self.n_vocab] = word\n",
        "                self.n_vocab += 1\n",
        "\n",
        "def preprocess(corpus, source_max_length, target_max_length):\n",
        "    print(\"Reading corpus...\")\n",
        "    pairs = []\n",
        "    for line in corpus:\n",
        "        pairs.append([s for s in line.strip().lower().split(\"  \")])\n",
        "    print(f\"Read {len(pairs)} sentence pairs\")\n",
        "\n",
        "    source_vocab = Vocab()\n",
        "    target_vocab = Vocab()\n",
        "\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        source_vocab.add_vocab(pair[0])\n",
        "        target_vocab.add_vocab(pair[1])\n",
        "\n",
        "    print(f\"Source vocab size = {source_vocab.n_vocab}\")\n",
        "    print(f\"Target vocab size = {target_vocab.n_vocab}\")\n",
        "\n",
        "    return pairs, source_vocab, target_vocab\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = self.embedding(x).view(1, 1, -1)\n",
        "        x, hidden = self.gru(x, hidden)\n",
        "        return x, hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = self.embedding(x).view(1, 1, -1)\n",
        "        x, hidden = self.gru(x, hidden)\n",
        "        x = self.softmax(self.out(x[0]))\n",
        "        return x, hidden\n",
        "\n",
        "def tensorize(vocab, sentence):\n",
        "    indexes = [vocab.vocab2index[word] for word in sentence.split()]\n",
        "    indexes.append(vocab.vocab2index[\"<EOS>\"])\n",
        "    return torch.Tensor(indexes).long().to(device).view(-1, 1)\n",
        "\n",
        "def train(pairs, source_vocab, target_vocab, encoder, decoder, n_iter, print_every=1000, learning_rate=0.01):\n",
        "    loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    training_batch = [random.choice(pairs) for _ in range(n_iter)]\n",
        "    training_source = [tensorize(source_vocab, pair[0]) for pair in training_batch]\n",
        "    training_target = [tensorize(target_vocab, pair[1]) for pair in training_batch]\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for i in range(1, n_iter + 1):\n",
        "        source_tensor = training_source[i - 1]\n",
        "        target_tensor = training_target[i - 1]\n",
        "\n",
        "        encoder_hidden = torch.zeros([1, 1, encoder.hidden_size]).to(device)\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        source_length = source_tensor.size(0)\n",
        "        target_length = target_tensor.size(0)\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        for enc_input in range(source_length):\n",
        "            _, encoder_hidden = encoder(source_tensor[enc_input], encoder_hidden)\n",
        "\n",
        "        decoder_input = torch.Tensor([[SOS_token]]).long().to(device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        loss_iter = loss.item() / target_length\n",
        "        loss_total += loss_iter\n",
        "\n",
        "        if i % print_every == 0:\n",
        "            loss_avg = loss_total / print_every\n",
        "            loss_total = 0\n",
        "            print(f\"[{i} - {i / n_iter * 100:.2f}%] loss = {loss_avg:.4f}\")\n",
        "\n",
        "def evaluate(pairs, source_vocab, target_vocab, encoder, decoder, max_length):\n",
        "    pair = random.choice(pairs)\n",
        "    source_sentence = pair[0]\n",
        "    target_sentence = pair[1]\n",
        "\n",
        "    print(f\"Source: {source_sentence}\")\n",
        "    print(f\"Target: {target_sentence}\")\n",
        "\n",
        "    source_tensor = tensorize(source_vocab, source_sentence)\n",
        "    encoder_hidden = torch.zeros([1, 1, encoder.hidden_size]).to(device)\n",
        "\n",
        "    source_length = source_tensor.size(0)\n",
        "\n",
        "    for enc_input in range(source_length):\n",
        "        _, encoder_hidden = encoder(source_tensor[enc_input], encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.Tensor([[SOS_token]]).long().to(device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    decoded_words = []\n",
        "\n",
        "    for di in range(max_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        topv, topi = decoder_output.topk(1)\n",
        "        if topi.item() == EOS_token:\n",
        "            break\n",
        "        else:\n",
        "            decoded_words.append(target_vocab.index2vocab[topi.item()])\n",
        "\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    print(\"Predicted:\", \" \".join(decoded_words))\n",
        "\n",
        "# Example corpus\n",
        "raw = [\n",
        "    \"I feel hungry.  나는 배가 고프다\",\n",
        "    \"Pytorch is very easy.  파이토치는 매우 쉽다.\",\n",
        "    \"Pytorch is a framework for deep learning.  파이토치는 딥러닝을 위한 프레임워크이다.\",\n",
        "    \"Pytorch is very clear to use.  파이토치는 사용하기 매우 직관적이다.\"\n",
        "]\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "# Preprocess data\n",
        "SOURCE_MAX_LENGTH = 10\n",
        "TARGET_MAX_LENGTH = 12\n",
        "load_pairs, load_source_vocab, load_target_vocab = preprocess(raw, SOURCE_MAX_LENGTH, TARGET_MAX_LENGTH)\n",
        "\n",
        "# Define encoder and decoder\n",
        "enc_hidden_size = 16\n",
        "dec_hidden_size = enc_hidden_size\n",
        "enc = Encoder(load_source_vocab.n_vocab, enc_hidden_size).to(device)\n",
        "dec = Decoder(dec_hidden_size, load_target_vocab.n_vocab).to(device)\n",
        "\n",
        "# Train model\n",
        "train(load_pairs, load_source_vocab, load_target_vocab, enc, dec, 5000, print_every=1000)\n",
        "\n",
        "# Evaluate model\n",
        "evaluate(load_pairs, load_source_vocab, load_target_vocab, enc, dec, TARGET_MAX_LENGTH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtvPPqP-Mhwv",
        "outputId": "604c89af-01b8-4a8d-c954-06991210c3f4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading corpus...\n",
            "Read 4 sentence pairs\n",
            "Counting words...\n",
            "Source vocab size = 17\n",
            "Target vocab size = 13\n",
            "[1000 - 20.00%] loss = 0.7389\n",
            "[2000 - 40.00%] loss = 0.1096\n",
            "[3000 - 60.00%] loss = 0.0345\n",
            "[4000 - 80.00%] loss = 0.0182\n",
            "[5000 - 100.00%] loss = 0.0124\n",
            "Source: i feel hungry.\n",
            "Target: 나는 배가 고프다\n",
            "Predicted: 나는 배가 고프다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dog:\n",
        "\tdef __init__(self, name):\n",
        "\t\tself.name = name\n",
        "\t\tself.tricks = []\n",
        "\n",
        "\tdef add_trick(self, trick):\n",
        "\t\tself.tricks.append(trick)\n",
        "\n",
        "d = Dog('Fido')\n",
        "e = Dog('Buddy')\n",
        "d.add_trick('roll over')\n",
        "e.add_trick('play dead')\n",
        "d.tricks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17XttEjm1T35",
        "outputId": "e9a7958d-e454-4b8c-e2d7-d8a9f54529f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['roll over']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}